{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b322ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3070, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import string\n",
    "import itertools\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GlobalMaxPool1D, BatchNormalization, Dense, RNN, GRU, LSTM, TimeDistributed, Bidirectional, Activation, Embedding, Input, Conv1D, Dropout\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from transformers import TFAutoModelForSequenceClassification, TFTrainingArguments, TFTrainer\n",
    "from scipy.special import softmax\n",
    "from datasets import DatasetDict, Dataset\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Define mixed precision policy\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d17040f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  Id\n",
       "0  My wife took me here on my birthday for breakf...      1   1\n",
       "1  I have no idea why some people give bad review...      1   2\n",
       "2  love the gyro plate. Rice is so good and I als...      1   3\n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      1   4\n",
       "4  General Manager Scott Petello is a good egg!!!...      1   5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data read and formatting\n",
    "df = pd.read_csv('yelp.csv')\n",
    "df = df.drop(['business_id', 'date', 'review_id', 'type', 'user_id', 'useful', 'funny', 'cool'], axis = 1)\n",
    "df['Label'] = np.where(df['stars'] >= 3, 1, 0)\n",
    "df['Id'] = range(1,len(df)+1)\n",
    "df = df.drop('stars', axis = 1)\n",
    "df.columns = ['Text', 'Label', 'Id']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13909eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty indices: []\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "reviews = [s.translate(translator) for s in list(df['Text'])]\n",
    "\n",
    "# Tokenization, Lemmatization, Stemming, Stopwords. Label numerical encoding\n",
    "reviews_tokenized = []\n",
    "reviews_tokenized_joined = []\n",
    "for review in reviews:\n",
    "  splitted_review = nltk.word_tokenize(review)\n",
    "  splitted_review = [word for word in splitted_review if word not in stop_words]\n",
    "  splitted_review = [WordNetLemmatizer().lemmatize(w) for w in splitted_review]\n",
    "  splitted_review = [PorterStemmer().stem(w).strip() for w in splitted_review]\n",
    "  reviews_tokenized.append(splitted_review)\n",
    "  joined_review = ' '.join(splitted_review)\n",
    "  reviews_tokenized_joined.append(joined_review)\n",
    "  \n",
    "# Remove empty reviews and the corresponding labels\n",
    "empty_idx = []\n",
    "for i, review in enumerate(reviews_tokenized):\n",
    "  if len(review) == 0:\n",
    "    empty_idx.append(i)\n",
    "\n",
    "print(f'Empty indices: {empty_idx}')\n",
    "labels = list(df['Label'])\n",
    "\n",
    "for i in empty_idx:\n",
    "  reviews_tokenized.pop(i)\n",
    "  reviews_tokenized_joined.pop(i)\n",
    "  reviews.pop(i)\n",
    "  labels.pop(i)\n",
    "  \n",
    "reviews_unrolled = list(itertools.chain(*reviews_tokenized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f42d4",
   "metadata": {},
   "source": [
    "### Part 1. Multinomial Naive Bayes with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e43da278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB CountVectorizer Training time: 0.35 seconds\n",
      "MultinomialNB CountVectorizer Accuracy score:  0.872\n",
      "MultinomialNB CountVectorizer Precision score:  0.8908587257617728\n",
      "MultinomialNB CountVectorizer Recall score:  0.9646070785842832\n",
      "MultinomialNB CountVectorizer F1 score:  0.9262672811059908\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews_tokenized_joined, labels, test_size = 0.2, random_state = 1)\n",
    "\n",
    "MultinomialNB_CountVectorizer_start_time = time.time()\n",
    "\n",
    "# Count vectorizer feature transformation\n",
    "count_vector = CountVectorizer(stop_words = 'english', binary = False)\n",
    "\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "test_data = count_vector.transform(X_test)\n",
    "\n",
    "# Multinomial Naive Bayes model predictions\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)\n",
    "\n",
    "MultinomialNB_CountVectorizer_predictions = naive_bayes.predict(test_data)\n",
    "\n",
    "MultinomialNB_CountVectorizer_end_time = time.time()\n",
    "MultinomialNB_CountVectorizer_execution_time = MultinomialNB_CountVectorizer_end_time - MultinomialNB_CountVectorizer_start_time\n",
    "\n",
    "# Model evaluation\n",
    "print('MultinomialNB CountVectorizer Training time: {} seconds'. format(round(MultinomialNB_CountVectorizer_execution_time, 2)))\n",
    "print('MultinomialNB CountVectorizer Accuracy score: ', format(accuracy_score(y_test, MultinomialNB_CountVectorizer_predictions)))\n",
    "print('MultinomialNB CountVectorizer Precision score: ', format(precision_score(y_test, MultinomialNB_CountVectorizer_predictions)))\n",
    "print('MultinomialNB CountVectorizer Recall score: ', format(recall_score(y_test, MultinomialNB_CountVectorizer_predictions)))\n",
    "print('MultinomialNB CountVectorizer F1 score: ', format(f1_score(y_test, MultinomialNB_CountVectorizer_predictions)))\n",
    "\n",
    "# Model evaluation dictionary\n",
    "MultinomialNB_CountVectorizer_results = {'Name': \"MultinomialNB CountVectorizer\", \n",
    "                                         \"Training Time\": round(MultinomialNB_CountVectorizer_execution_time, 2),\n",
    "                                         \"Accuracy score\": accuracy_score(y_test, MultinomialNB_CountVectorizer_predictions),\n",
    "                                         \"Precision score\": precision_score(y_test, MultinomialNB_CountVectorizer_predictions),\n",
    "                                         \"Recall score\": recall_score(y_test, MultinomialNB_CountVectorizer_predictions),\n",
    "                                         \"F1 score\": f1_score(y_test, MultinomialNB_CountVectorizer_predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35547f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the results into a pickle file\n",
    "filename = 'results_dict_list_yelp.pickle'\n",
    "\n",
    "results_dict_list = [MultinomialNB_CountVectorizer_results]\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(results_dict_list, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d0987e",
   "metadata": {},
   "source": [
    "### Part 2. Multinomial Naive Bayes with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44f9eb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB tfidf Training time: 0.37 seconds\n",
      "MultinomialNB tfidf Accuracy score:  0.834\n",
      "MultinomialNB tfidf Precision score:  0.8339169584792396\n",
      "MultinomialNB tfidf Recall score:  1.0\n",
      "MultinomialNB tfidf F1 score:  0.9094380796508457\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews_tokenized_joined, labels, test_size = 0.2, random_state = 1)\n",
    "\n",
    "MultinomialNB_tfidf_start_time = time.time()\n",
    "\n",
    "# TF-IDF feature transformation\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', binary = False)\n",
    "\n",
    "training_data = tfidf.fit_transform(X_train)\n",
    "test_data = tfidf.transform(X_test)\n",
    "\n",
    "# Multinomial Naive Bayes model predictions\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)\n",
    "\n",
    "MultinomialNB_tfidf_predictions = naive_bayes.predict(test_data)\n",
    "\n",
    "MultinomialNB_tfidf_end_time = time.time()\n",
    "MultinomialNB_tfidf_execution_time = MultinomialNB_tfidf_end_time - MultinomialNB_tfidf_start_time\n",
    "\n",
    "# Model evaluation\n",
    "print('MultinomialNB tfidf Training time: {} seconds'. format(round(MultinomialNB_tfidf_execution_time, 2)))\n",
    "print('MultinomialNB tfidf Accuracy score: ', format(accuracy_score(y_test, MultinomialNB_tfidf_predictions)))\n",
    "print('MultinomialNB tfidf Precision score: ', format(precision_score(y_test, MultinomialNB_tfidf_predictions)))\n",
    "print('MultinomialNB tfidf Recall score: ', format(recall_score(y_test, MultinomialNB_tfidf_predictions)))\n",
    "print('MultinomialNB tfidf F1 score: ', format(f1_score(y_test, MultinomialNB_tfidf_predictions)))\n",
    "\n",
    "# Model evaluation dictionary\n",
    "MultinomialNB_tfidf_results = {'Name': \"MultinomialNB tfidf\", \n",
    "                                         \"Training Time\": round(MultinomialNB_tfidf_execution_time, 2),\n",
    "                                         \"Accuracy score\": accuracy_score(y_test, MultinomialNB_tfidf_predictions),\n",
    "                                         \"Precision score\": precision_score(y_test, MultinomialNB_tfidf_predictions),\n",
    "                                         \"Recall score\": recall_score(y_test, MultinomialNB_tfidf_predictions),\n",
    "                                         \"F1 score\": f1_score(y_test, MultinomialNB_tfidf_predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7da6c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the results pickle file\n",
    "def update_the_results_file(model_name, filename=filename):\n",
    "  with open(filename, 'rb') as f:\n",
    "    results_dict_list = pickle.load(f)\n",
    "    \n",
    "  results_dict_list.append(model_name)\n",
    "\n",
    "  with open(filename, 'wb') as f:\n",
    "      pickle.dump(results_dict_list, f)\n",
    "      \n",
    "update_the_results_file(model_name = MultinomialNB_tfidf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ce55da",
   "metadata": {},
   "source": [
    "### Part 3. Vaders sentiment classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c6b710",
   "metadata": {},
   "source": [
    "#### Extra preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ae34c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>love the gyro plate Rice is so good and I also...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rosie Dakota and I LOVE Chaparral Dog Park Its...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg No...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               Text  Label\n",
       "0   1  My wife took me here on my birthday for breakf...      1\n",
       "1   2  I have no idea why some people give bad review...      1\n",
       "2   3  love the gyro plate Rice is so good and I also...      1\n",
       "3   4  Rosie Dakota and I LOVE Chaparral Dog Park Its...      1\n",
       "4   5  General Manager Scott Petello is a good egg No...      1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe for convenience\n",
    "df = pd.DataFrame({'Text': reviews, 'Label': labels})\n",
    "df = df.reset_index()\n",
    "df['Id'] = df['index'] + 1\n",
    "df.drop('index', axis = 1, inplace = True)\n",
    "df = df[['Id', 'Text', 'Label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2720843c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07617a243c4b44f282cc525e8d4c8d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Predicted_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.8377</td>\n",
       "      <td>love the gyro plate Rice is so good and I also...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>Rosie Dakota and I LOVE Chaparral Dog Park Its...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>General Manager Scott Petello is a good egg No...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    neg    neu    pos  compound  \\\n",
       "0   1  0.015  0.688  0.297    0.9950   \n",
       "1   2  0.048  0.736  0.215    0.9945   \n",
       "2   3  0.000  0.602  0.398    0.8377   \n",
       "3   4  0.000  0.805  0.195    0.9436   \n",
       "4   5  0.031  0.648  0.321    0.9848   \n",
       "\n",
       "                                                Text  Label  Predicted_Label  \n",
       "0  My wife took me here on my birthday for breakf...      1                1  \n",
       "1  I have no idea why some people give bad review...      1                1  \n",
       "2  love the gyro plate Rice is so good and I also...      1                1  \n",
       "3  Rosie Dakota and I LOVE Chaparral Dog Park Its...      1                1  \n",
       "4  General Manager Scott Petello is a good egg No...      1                1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_start_time = time.time()\n",
    "\n",
    "# Define Vader Sentiment analyzer model\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Get the results\n",
    "res = {}\n",
    "for i, row in tqdm(df.iterrows(), total = len(df)):\n",
    "  text = row['Text']\n",
    "  myid = row['Id']\n",
    "  res[myid] = sia.polarity_scores(text)\n",
    "  \n",
    "vaders = pd.DataFrame(res).T\n",
    "vaders = vaders.reset_index().rename(columns = {'index': 'Id'})\n",
    "vaders = vaders.merge(df, how = 'left')\n",
    "vaders['Predicted_Label'] = np.where(vaders['compound'] >= 0, 1, 0)\n",
    "\n",
    "vader_end_time = time.time()\n",
    "vader_execution_time = vader_end_time - vader_start_time\n",
    "\n",
    "vaders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a847151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader Training time: 8.74 seconds\n",
      "Vader Accuracy score:  0.8689\n",
      "Vader Precision score:  0.8883597297596633\n",
      "Vader Recall score:  0.9635992311388756\n",
      "Vader F1 score:  0.9244511035555812\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "print('Vader Training time: {} seconds'. format(round(vader_execution_time, 2)))\n",
    "print('Vader Accuracy score: ', format(accuracy_score(vaders['Label'], vaders['Predicted_Label'])))\n",
    "print('Vader Precision score: ', format(precision_score(vaders['Label'], vaders['Predicted_Label'])))\n",
    "print('Vader Recall score: ', format(recall_score(vaders['Label'], vaders['Predicted_Label'])))\n",
    "print('Vader F1 score: ', format(f1_score(vaders['Label'], vaders['Predicted_Label'])))\n",
    "\n",
    "# Model evaluation dictionary\n",
    "vader_results = {'Name': \"Vaders Analyser\", \n",
    "                                         \"Training Time\": round(vader_execution_time, 2),\n",
    "                                         \"Accuracy score\": accuracy_score(vaders['Label'], vaders['Predicted_Label']),\n",
    "                                         \"Precision score\": precision_score(vaders['Label'], vaders['Predicted_Label']),\n",
    "                                         \"Recall score\": recall_score(vaders['Label'], vaders['Predicted_Label']),\n",
    "                                         \"F1 score\": f1_score(vaders['Label'], vaders['Predicted_Label'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c92e3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_the_results_file(model_name = vader_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4763fa",
   "metadata": {},
   "source": [
    "### Part 4. RNN manual implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcd84150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary, word2index reference and convert the reviews into numerical form\n",
    "vocab_size = 10000\n",
    "\n",
    "word_counter = Counter(reviews_unrolled)\n",
    "word_counter = dict(word_counter.most_common(vocab_size))\n",
    "word2index = {k:i for i,k in enumerate(word_counter.keys(), start = 3)}\n",
    "\n",
    "# Convert reveies to integers\n",
    "reviews_int = []\n",
    "for review in reviews_tokenized:\n",
    "  cur_review = [1]\n",
    "  for word in review:\n",
    "    if word in word2index.keys():\n",
    "      cur_review.append(word2index[word])\n",
    "    else:\n",
    "      cur_review.append(2)\n",
    "  reviews_int.append(cur_review)\n",
    "  \n",
    "# Pad sequences\n",
    "padded_reviews = pad_sequences(reviews_int, maxlen = 500, padding = 'pre', truncating = 'pre')\n",
    "\n",
    "# Train test split on padded sequences\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_reviews, labels, test_size = 0.2, random_state = 1)\n",
    "\n",
    "X_train = np.array(X_train).reshape(8000, 500)\n",
    "X_test = np.array(X_test).reshape(2000, 500)\n",
    "\n",
    "y_train = np.array(y_train).reshape(8000, 1)\n",
    "y_test = np.array(y_test).reshape(2000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0df12945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 500)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 500, 128)          1280000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 500, 200)          333000    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 500, 200)         800       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 500, 200)          0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 500, 128)          126720    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 500, 128)         512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500, 128)          0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               66048     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,907,177\n",
      "Trainable params: 1,906,265\n",
      "Non-trainable params: 912\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# Model checkpoint callback\n",
    "checkpoint = ModelCheckpoint(filepath='best_RNN_manual_model_amazon.h5', \n",
    "                             monitor='val_loss', \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto')\n",
    "\n",
    "# Early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           patience=3, \n",
    "                           verbose=1, \n",
    "                           restore_best_weights=True)\n",
    "\n",
    "inputs = Input(shape = (X_train.shape[1:]))\n",
    "mask = tf.keras.layers.Lambda(lambda inputs: K.not_equal(inputs, 0))(inputs)\n",
    "x = Embedding(input_dim = vocab_size, output_dim = 128, input_length = 200)(inputs)\n",
    "x = Conv1D(filters = 200, kernel_size = 13, strides = 1, padding = 'same', activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = GRU(128, return_sequences = True)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = GRU(128, return_sequences = False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "outputs = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13482a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "Manual_RNN_start_time = time.time()\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 10, batch_size = 128, validation_data = (X_test, y_test), callbacks = [checkpoint, early_stop])\n",
    "\n",
    "Manual_RNN_end_time = time.time()\n",
    "Manual_RNN_execution_time = Manual_RNN_end_time - Manual_RNN_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad1d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139038f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36da41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a44f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a8cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
